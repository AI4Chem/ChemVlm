2024-07-09 14:25:29 | INFO | model_worker | args: Namespace(host='0.0.0.0', port=10062, worker_address='http://10.140.24.69:10062', controller_address='http://10.140.24.69:10050', model_path='/mnt/hwfile/ai4chem/CKPT/wxz/chemvl_2B_ft_7_3_0_merge', model_base=None, model_name='chemvlm_2B', device='auto', multi_modal=False, limit_model_concurrency=5, stream_interval=1, no_register=False, load_8bit=False, load_4bit=False)
2024-07-09 14:25:29 | INFO | model_worker | Loading the model chemvlm_2B on worker 0cb6b7 ...
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
2024-07-09 14:25:29 | INFO | internvl.model.internvl_chat.configuration_internvl_chat | vision_select_layer: -1
2024-07-09 14:25:29 | INFO | internvl.model.internvl_chat.configuration_internvl_chat | ps_version: v2
2024-07-09 14:25:29 | INFO | internvl.model.internvl_chat.configuration_internvl_chat | min_dynamic_patch: 1
2024-07-09 14:25:29 | INFO | internvl.model.internvl_chat.configuration_internvl_chat | max_dynamic_patch: 6
2024-07-09 14:25:29 | INFO | internvl.model.internvl_chat.modeling_internvl_chat | num_image_token: 256
2024-07-09 14:25:29 | INFO | internvl.model.internvl_chat.modeling_internvl_chat | ps_version: v2
2024-07-09 14:25:33 | INFO | accelerate.utils.modeling | We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
2024-07-09 14:25:34 | ERROR | stderr | Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]
2024-07-09 14:25:49 | ERROR | stderr | Loading checkpoint shards:  50%|█████     | 1/2 [00:15<00:15, 15.85s/it]
2024-07-09 14:25:59 | ERROR | stderr | Loading checkpoint shards: 100%|██████████| 2/2 [00:25<00:00, 12.12s/it]
2024-07-09 14:25:59 | ERROR | stderr | Loading checkpoint shards: 100%|██████████| 2/2 [00:25<00:00, 12.68s/it]
2024-07-09 14:25:59 | ERROR | stderr | 
Some weights of InternVLChatModel were not initialized from the model checkpoint at /mnt/hwfile/ai4chem/CKPT/wxz/chemvl_2B_ft_7_3_0_merge and are newly initialized: ['vision_model.encoder.layers.0.norm1.bias', 'vision_model.encoder.layers.0.norm2.bias', 'vision_model.encoder.layers.1.norm1.bias', 'vision_model.encoder.layers.1.norm2.bias', 'vision_model.encoder.layers.10.norm1.bias', 'vision_model.encoder.layers.10.norm2.bias', 'vision_model.encoder.layers.11.norm1.bias', 'vision_model.encoder.layers.11.norm2.bias', 'vision_model.encoder.layers.12.norm1.bias', 'vision_model.encoder.layers.12.norm2.bias', 'vision_model.encoder.layers.13.norm1.bias', 'vision_model.encoder.layers.13.norm2.bias', 'vision_model.encoder.layers.14.norm1.bias', 'vision_model.encoder.layers.14.norm2.bias', 'vision_model.encoder.layers.15.norm1.bias', 'vision_model.encoder.layers.15.norm2.bias', 'vision_model.encoder.layers.16.norm1.bias', 'vision_model.encoder.layers.16.norm2.bias', 'vision_model.encoder.layers.17.norm1.bias', 'vision_model.encoder.layers.17.norm2.bias', 'vision_model.encoder.layers.18.norm1.bias', 'vision_model.encoder.layers.18.norm2.bias', 'vision_model.encoder.layers.19.norm1.bias', 'vision_model.encoder.layers.19.norm2.bias', 'vision_model.encoder.layers.2.norm1.bias', 'vision_model.encoder.layers.2.norm2.bias', 'vision_model.encoder.layers.20.norm1.bias', 'vision_model.encoder.layers.20.norm2.bias', 'vision_model.encoder.layers.21.norm1.bias', 'vision_model.encoder.layers.21.norm2.bias', 'vision_model.encoder.layers.22.norm1.bias', 'vision_model.encoder.layers.22.norm2.bias', 'vision_model.encoder.layers.23.norm1.bias', 'vision_model.encoder.layers.23.norm2.bias', 'vision_model.encoder.layers.3.norm1.bias', 'vision_model.encoder.layers.3.norm2.bias', 'vision_model.encoder.layers.4.norm1.bias', 'vision_model.encoder.layers.4.norm2.bias', 'vision_model.encoder.layers.5.norm1.bias', 'vision_model.encoder.layers.5.norm2.bias', 'vision_model.encoder.layers.6.norm1.bias', 'vision_model.encoder.layers.6.norm2.bias', 'vision_model.encoder.layers.7.norm1.bias', 'vision_model.encoder.layers.7.norm2.bias', 'vision_model.encoder.layers.8.norm1.bias', 'vision_model.encoder.layers.8.norm2.bias', 'vision_model.encoder.layers.9.norm1.bias', 'vision_model.encoder.layers.9.norm2.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
2024-07-09 14:25:59 | INFO | model_worker | Register to controller
2024-07-09 14:25:59 | ERROR | stderr | INFO:     Started server process [38983]
2024-07-09 14:25:59 | ERROR | stderr | INFO:     Waiting for application startup.
2024-07-09 14:25:59 | ERROR | stderr | INFO:     Application startup complete.
2024-07-09 14:25:59 | ERROR | stderr | INFO:     Uvicorn running on http://0.0.0.0:10062 (Press CTRL+C to quit)
2024-07-09 14:26:14 | INFO | model_worker | Send heart beat. Models: ['chemvlm_2B']. Semaphore: None. global_counter: 0
2024-07-09 14:26:29 | INFO | model_worker | Send heart beat. Models: ['chemvlm_2B']. Semaphore: None. global_counter: 0
2024-07-09 14:26:44 | INFO | model_worker | Send heart beat. Models: ['chemvlm_2B']. Semaphore: None. global_counter: 0
2024-07-09 14:26:59 | INFO | model_worker | Send heart beat. Models: ['chemvlm_2B']. Semaphore: None. global_counter: 0
2024-07-09 14:27:14 | INFO | model_worker | Send heart beat. Models: ['chemvlm_2B']. Semaphore: None. global_counter: 0
2024-07-09 14:27:30 | INFO | model_worker | Send heart beat. Models: ['chemvlm_2B']. Semaphore: None. global_counter: 0
2024-07-09 14:27:45 | INFO | model_worker | Send heart beat. Models: ['chemvlm_2B']. Semaphore: None. global_counter: 0
2024-07-09 14:27:55 | INFO | stdout | INFO:     10.140.24.69:59771 - "POST /worker_get_status HTTP/1.1" 200 OK
2024-07-09 14:28:00 | INFO | model_worker | Send heart beat. Models: ['chemvlm_2B']. Semaphore: None. global_counter: 0
2024-07-09 14:28:15 | INFO | model_worker | Send heart beat. Models: ['chemvlm_2B']. Semaphore: None. global_counter: 0
2024-07-09 14:28:16 | INFO | model_worker | Send heart beat. Models: ['chemvlm_2B']. Semaphore: Semaphore(value=4, locked=False). global_counter: 1
2024-07-09 14:28:16 | INFO | stdout | INFO:     10.140.24.69:59885 - "POST /worker_generate_stream HTTP/1.1" 200 OK
2024-07-09 14:28:16 | INFO | model_worker | max_input_tiles: 12
2024-07-09 14:28:16 | INFO | model_worker | dynamic_image_size: False
2024-07-09 14:28:16 | INFO | model_worker | use_thumbnail: False
2024-07-09 14:28:16 | INFO | model_worker | Resize images to 448x448
2024-07-09 14:28:16 | INFO | model_worker | Split images to torch.Size([1, 3, 448, 448])
2024-07-09 14:28:16 | INFO | model_worker | A chat between a curious user and an artificial intelligence assistant. The assistant gives helpful, detailed, and polite answers to the user's questions. USER: <img><image></img>
what is this ASSISTANT:
2024-07-09 14:28:16 | INFO | model_worker | num_image_tokens: 256
2024-07-09 14:28:16 | INFO | model_worker | max_new_tokens: 1024
2024-07-09 14:28:21 | ERROR | stderr | Exception in thread Thread-3:
2024-07-09 14:28:21 | ERROR | stderr | Traceback (most recent call last):
2024-07-09 14:28:21 | ERROR | stderr |   File "/mnt/petrelfs/zhangdi1/miniforge3/envs/internvl_new/lib/python3.9/threading.py", line 980, in _bootstrap_inner
2024-07-09 14:28:21 | ERROR | stderr |     self.run()
2024-07-09 14:28:21 | ERROR | stderr |   File "/mnt/petrelfs/zhangdi1/miniforge3/envs/internvl_new/lib/python3.9/threading.py", line 917, in run
2024-07-09 14:28:21 | ERROR | stderr |     self._target(*self._args, **self._kwargs)
2024-07-09 14:28:21 | ERROR | stderr |   File "/mnt/petrelfs/zhangdi1/miniforge3/envs/internvl_new/lib/python3.9/site-packages/torch/utils/_contextlib.py", line 115, in decorate_context
2024-07-09 14:28:21 | ERROR | stderr |     return func(*args, **kwargs)
2024-07-09 14:28:21 | ERROR | stderr |   File "/mnt/petrelfs/zhangdi1/lijunxian/InternVL/internvl_chat/internvl/model/internvl_chat/modeling_internvl_chat.py", line 383, in generate
2024-07-09 14:28:21 | ERROR | stderr |     outputs = self.language_model.generate(
2024-07-09 14:28:21 | ERROR | stderr |   File "/mnt/petrelfs/zhangdi1/miniforge3/envs/internvl_new/lib/python3.9/site-packages/torch/utils/_contextlib.py", line 115, in decorate_context
2024-07-09 14:28:21 | ERROR | stderr |     return func(*args, **kwargs)
2024-07-09 14:28:21 | ERROR | stderr |   File "/mnt/petrelfs/zhangdi1/miniforge3/envs/internvl_new/lib/python3.9/site-packages/transformers/generation/utils.py", line 1525, in generate
2024-07-09 14:28:21 | ERROR | stderr |     return self.sample(
2024-07-09 14:28:21 | ERROR | stderr |   File "/mnt/petrelfs/zhangdi1/miniforge3/envs/internvl_new/lib/python3.9/site-packages/transformers/generation/utils.py", line 2658, in sample
2024-07-09 14:28:21 | ERROR | stderr |     next_tokens = torch.multinomial(probs, num_samples=1).squeeze(1)
2024-07-09 14:28:21 | ERROR | stderr | RuntimeError: probability tensor contains either `inf`, `nan` or element < 0
2024-07-09 14:28:30 | INFO | model_worker | Send heart beat. Models: ['chemvlm_2B']. Semaphore: Semaphore(value=4, locked=False). global_counter: 1
2024-07-09 14:28:31 | INFO | stdout | Caught Unknown Error
2024-07-09 14:28:31 | INFO | model_worker | Send heart beat. Models: ['chemvlm_2B']. Semaphore: Semaphore(value=5, locked=False). global_counter: 1
2024-07-09 14:28:45 | INFO | model_worker | Send heart beat. Models: ['chemvlm_2B']. Semaphore: Semaphore(value=5, locked=False). global_counter: 1
2024-07-09 14:29:00 | INFO | model_worker | Send heart beat. Models: ['chemvlm_2B']. Semaphore: Semaphore(value=5, locked=False). global_counter: 1
2024-07-09 14:29:15 | INFO | model_worker | Send heart beat. Models: ['chemvlm_2B']. Semaphore: Semaphore(value=5, locked=False). global_counter: 1
2024-07-09 14:29:30 | INFO | model_worker | Send heart beat. Models: ['chemvlm_2B']. Semaphore: Semaphore(value=5, locked=False). global_counter: 1
2024-07-09 14:29:45 | INFO | model_worker | Send heart beat. Models: ['chemvlm_2B']. Semaphore: Semaphore(value=5, locked=False). global_counter: 1
2024-07-09 14:30:00 | INFO | model_worker | Send heart beat. Models: ['chemvlm_2B']. Semaphore: Semaphore(value=5, locked=False). global_counter: 1
2024-07-09 14:30:15 | INFO | model_worker | Send heart beat. Models: ['chemvlm_2B']. Semaphore: Semaphore(value=5, locked=False). global_counter: 1
2024-07-09 14:30:30 | INFO | model_worker | Send heart beat. Models: ['chemvlm_2B']. Semaphore: Semaphore(value=5, locked=False). global_counter: 1
2024-07-09 14:30:45 | INFO | model_worker | Send heart beat. Models: ['chemvlm_2B']. Semaphore: Semaphore(value=5, locked=False). global_counter: 1
2024-07-09 14:31:00 | INFO | model_worker | Send heart beat. Models: ['chemvlm_2B']. Semaphore: Semaphore(value=5, locked=False). global_counter: 1
2024-07-09 14:31:15 | INFO | model_worker | Send heart beat. Models: ['chemvlm_2B']. Semaphore: Semaphore(value=5, locked=False). global_counter: 1
2024-07-09 14:31:30 | INFO | model_worker | Send heart beat. Models: ['chemvlm_2B']. Semaphore: Semaphore(value=5, locked=False). global_counter: 1
2024-07-09 14:31:45 | INFO | model_worker | Send heart beat. Models: ['chemvlm_2B']. Semaphore: Semaphore(value=5, locked=False). global_counter: 1
2024-07-09 14:32:00 | INFO | model_worker | Send heart beat. Models: ['chemvlm_2B']. Semaphore: Semaphore(value=5, locked=False). global_counter: 1
slurmstepd: error: *** JOB 3675352 ON SH-IDC1-10-140-24-69 CANCELLED AT 2024-07-09T14:32:06 ***
2024-07-09 14:32:06 | ERROR | stderr | INFO:     Shutting down
