2024-05-29 21:06:42 | INFO | model_worker | args: Namespace(host='0.0.0.0', port=10014, worker_address='http://10.140.24.69:10014', controller_address='http://10.140.24.69:10010', model_path='/mnt/hwfile/ai4chem/share/multimodal-exam/internvl_chemllm-llm_lora', model_base=None, model_name='test', device='auto', multi_modal=False, limit_model_concurrency=5, stream_interval=1, no_register=False, load_8bit=False, load_4bit=False)
2024-05-29 21:06:42 | INFO | model_worker | Loading the model test on worker 55affd ...
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
2024-05-29 21:06:43 | INFO | internvl.model.internvl_chat.configuration_internvl_chat | vision_select_layer: -1
2024-05-29 21:06:43 | INFO | internvl.model.internvl_chat.configuration_internvl_chat | ps_version: v1
2024-05-29 21:06:43 | INFO | internvl.model.internvl_chat.configuration_internvl_chat | min_dynamic_patch: 1
2024-05-29 21:06:43 | INFO | internvl.model.internvl_chat.configuration_internvl_chat | max_dynamic_patch: 6
2024-05-29 21:06:43 | INFO | internvl.model.internvl_chat.modeling_internvl_chat | num_image_token: 256
2024-05-29 21:06:43 | INFO | internvl.model.internvl_chat.modeling_internvl_chat | ps_version: v1
2024-05-29 21:06:46 | INFO | stdout | trainable params: 72,351,744 || all params: 19,933,612,032 || trainable%: 0.3630
2024-05-29 21:06:49 | INFO | accelerate.utils.modeling | We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
2024-05-29 21:06:53 | ERROR | stderr | Loading checkpoint shards:   0%|          | 0/11 [00:00<?, ?it/s]
2024-05-29 21:06:55 | ERROR | stderr | Loading checkpoint shards:   9%|▉         | 1/11 [00:02<00:22,  2.24s/it]
2024-05-29 21:06:57 | ERROR | stderr | Loading checkpoint shards:  18%|█▊        | 2/11 [00:04<00:20,  2.32s/it]
2024-05-29 21:07:00 | ERROR | stderr | Loading checkpoint shards:  27%|██▋       | 3/11 [00:06<00:17,  2.23s/it]
2024-05-29 21:07:02 | ERROR | stderr | Loading checkpoint shards:  36%|███▋      | 4/11 [00:09<00:15,  2.28s/it]
2024-05-29 21:07:04 | ERROR | stderr | Loading checkpoint shards:  45%|████▌     | 5/11 [00:11<00:13,  2.30s/it]
2024-05-29 21:07:07 | ERROR | stderr | Loading checkpoint shards:  55%|█████▍    | 6/11 [00:13<00:11,  2.32s/it]
2024-05-29 21:07:09 | ERROR | stderr | Loading checkpoint shards:  64%|██████▎   | 7/11 [00:16<00:09,  2.35s/it]
2024-05-29 21:07:11 | ERROR | stderr | Loading checkpoint shards:  73%|███████▎  | 8/11 [00:18<00:07,  2.35s/it]
2024-05-29 21:07:14 | ERROR | stderr | Loading checkpoint shards:  82%|████████▏ | 9/11 [00:20<00:04,  2.33s/it]
2024-05-29 21:07:16 | ERROR | stderr | Loading checkpoint shards:  91%|█████████ | 10/11 [00:23<00:02,  2.32s/it]
2024-05-29 21:07:17 | ERROR | stderr | Loading checkpoint shards: 100%|██████████| 11/11 [00:24<00:00,  1.92s/it]
2024-05-29 21:07:17 | ERROR | stderr | Loading checkpoint shards: 100%|██████████| 11/11 [00:24<00:00,  2.20s/it]
2024-05-29 21:07:17 | ERROR | stderr | 
2024-05-29 21:07:17 | INFO | model_worker | Register to controller
2024-05-29 21:07:18 | ERROR | stderr | INFO:     Started server process [97533]
2024-05-29 21:07:18 | ERROR | stderr | INFO:     Waiting for application startup.
2024-05-29 21:07:18 | ERROR | stderr | INFO:     Application startup complete.
2024-05-29 21:07:18 | ERROR | stderr | INFO:     Uvicorn running on http://0.0.0.0:10014 (Press CTRL+C to quit)
2024-05-29 21:07:32 | INFO | stdout | INFO:     10.140.24.69:48430 - "POST /worker_get_status HTTP/1.1" 200 OK
2024-05-29 21:07:32 | INFO | model_worker | Send heart beat. Models: ['test']. Semaphore: None. global_counter: 0
2024-05-29 21:07:45 | INFO | model_worker | Send heart beat. Models: ['test']. Semaphore: Semaphore(value=4, locked=False). global_counter: 1
2024-05-29 21:07:45 | INFO | stdout | INFO:     10.140.24.69:48442 - "POST /worker_generate_stream HTTP/1.1" 200 OK
2024-05-29 21:07:45 | INFO | model_worker | max_input_tiles: 12
2024-05-29 21:07:45 | INFO | model_worker | dynamic_image_size: False
2024-05-29 21:07:45 | INFO | model_worker | use_thumbnail: False
2024-05-29 21:07:45 | INFO | model_worker | Resize images to 448x448
2024-05-29 21:07:45 | INFO | model_worker | Split images to torch.Size([1, 3, 448, 448])
2024-05-29 21:07:45 | INFO | model_worker | A chat between a curious user and an artificial intelligence assistant. The assistant gives helpful, detailed, and polite answers to the user's questions. USER: <img><image></img>
请描述这张图片 ASSISTANT:
2024-05-29 21:07:45 | INFO | model_worker | num_image_tokens: 256
2024-05-29 21:07:45 | INFO | model_worker | max_new_tokens: 1024
2024-05-29 21:07:47 | INFO | model_worker | Send heart beat. Models: ['test']. Semaphore: Semaphore(value=4, locked=False). global_counter: 1
2024-05-29 21:07:50 | ERROR | stderr | /mnt/petrelfs/zhangdi1/lijunxian/InternVL/internvl_chat/internvl/model/internvl_chat/modeling_internvl_chat.py:198: UserWarning: In ps_version 'v1', the height and width have not been swapped back, which results in a transposed image.
2024-05-29 21:07:50 | ERROR | stderr |   warnings.warn("In ps_version 'v1', the height and width have not been swapped back, "
2024-05-29 21:07:59 | INFO | model_worker | Send heart beat. Models: ['test']. Semaphore: Semaphore(value=5, locked=False). global_counter: 1
2024-05-29 21:08:00 | INFO | stdout | INFO:     10.140.24.69:48462 - "POST /worker_get_status HTTP/1.1" 200 OK
2024-05-29 21:08:03 | INFO | model_worker | Send heart beat. Models: ['test']. Semaphore: Semaphore(value=5, locked=False). global_counter: 1
2024-05-29 21:08:18 | INFO | model_worker | Send heart beat. Models: ['test']. Semaphore: Semaphore(value=5, locked=False). global_counter: 1
2024-05-29 21:08:33 | INFO | model_worker | Send heart beat. Models: ['test']. Semaphore: Semaphore(value=5, locked=False). global_counter: 1
2024-05-29 21:08:34 | INFO | model_worker | Send heart beat. Models: ['test']. Semaphore: Semaphore(value=4, locked=False). global_counter: 2
2024-05-29 21:08:34 | INFO | stdout | INFO:     10.140.24.69:48874 - "POST /worker_generate_stream HTTP/1.1" 200 OK
2024-05-29 21:08:34 | INFO | model_worker | max_input_tiles: 12
2024-05-29 21:08:35 | INFO | model_worker | dynamic_image_size: False
2024-05-29 21:08:35 | INFO | model_worker | use_thumbnail: False
2024-05-29 21:08:35 | INFO | model_worker | Resize images to 448x448
2024-05-29 21:08:35 | INFO | model_worker | Split images to torch.Size([1, 3, 448, 448])
2024-05-29 21:08:35 | INFO | model_worker | A chat between a curious user and an artificial intelligence assistant. The assistant gives helpful, detailed, and polite answers to the user's questions. USER: <img><image></img>
请描述这张图片 ASSISTANT:
2024-05-29 21:08:35 | INFO | model_worker | num_image_tokens: 256
2024-05-29 21:08:35 | INFO | model_worker | max_new_tokens: 1024
2024-05-29 21:08:48 | INFO | model_worker | Send heart beat. Models: ['test']. Semaphore: Semaphore(value=4, locked=False). global_counter: 2
2024-05-29 21:09:03 | INFO | model_worker | Send heart beat. Models: ['test']. Semaphore: Semaphore(value=4, locked=False). global_counter: 2
2024-05-29 21:09:09 | INFO | model_worker | Send heart beat. Models: ['test']. Semaphore: Semaphore(value=5, locked=False). global_counter: 2
2024-05-29 21:09:09 | INFO | stdout | INFO:     10.140.24.69:48896 - "POST /worker_get_status HTTP/1.1" 200 OK
2024-05-29 21:09:18 | INFO | model_worker | Send heart beat. Models: ['test']. Semaphore: Semaphore(value=5, locked=False). global_counter: 2
2024-05-29 21:09:32 | INFO | model_worker | Send heart beat. Models: ['test']. Semaphore: Semaphore(value=4, locked=False). global_counter: 3
2024-05-29 21:09:32 | INFO | stdout | INFO:     10.140.24.69:48912 - "POST /worker_generate_stream HTTP/1.1" 200 OK
2024-05-29 21:09:32 | INFO | model_worker | max_input_tiles: 12
2024-05-29 21:09:32 | INFO | model_worker | dynamic_image_size: False
2024-05-29 21:09:32 | INFO | model_worker | use_thumbnail: False
2024-05-29 21:09:32 | INFO | model_worker | Resize images to 448x448
2024-05-29 21:09:32 | INFO | model_worker | Split images to torch.Size([1, 3, 448, 448])
2024-05-29 21:09:32 | INFO | model_worker | A chat between a curious user and an artificial intelligence assistant. The assistant gives helpful, detailed, and polite answers to the user's questions. USER: <img><image></img>
请描述这张图片 ASSISTANT:
2024-05-29 21:09:32 | INFO | model_worker | num_image_tokens: 256
2024-05-29 21:09:32 | INFO | model_worker | max_new_tokens: 1024
2024-05-29 21:09:33 | INFO | model_worker | Send heart beat. Models: ['test']. Semaphore: Semaphore(value=4, locked=False). global_counter: 3
2024-05-29 21:09:48 | INFO | model_worker | Send heart beat. Models: ['test']. Semaphore: Semaphore(value=4, locked=False). global_counter: 3
2024-05-29 21:10:03 | INFO | model_worker | Send heart beat. Models: ['test']. Semaphore: Semaphore(value=4, locked=False). global_counter: 3
slurmstepd: error: *** JOB 3517386 ON SH-IDC1-10-140-24-69 CANCELLED AT 2024-05-29T21:10:05 ***
2024-05-29 21:10:05 | ERROR | stderr | INFO:     Shutting down
