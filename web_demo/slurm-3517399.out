2024-05-29 21:10:21 | INFO | model_worker | args: Namespace(host='0.0.0.0', port=10014, worker_address='http://10.140.24.69:10014', controller_address='http://10.140.24.69:10010', model_path='/mnt/hwfile/ai4chem/share/multimodal-exam/internvl_chemllm-llm_lora', model_base=None, model_name='test', device='auto', multi_modal=False, limit_model_concurrency=5, stream_interval=1, no_register=False, load_8bit=False, load_4bit=False)
2024-05-29 21:10:21 | INFO | model_worker | Loading the model test on worker d6a0fa ...
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
2024-05-29 21:10:21 | INFO | internvl.model.internvl_chat.configuration_internvl_chat | vision_select_layer: -1
2024-05-29 21:10:21 | INFO | internvl.model.internvl_chat.configuration_internvl_chat | ps_version: v1
2024-05-29 21:10:21 | INFO | internvl.model.internvl_chat.configuration_internvl_chat | min_dynamic_patch: 1
2024-05-29 21:10:21 | INFO | internvl.model.internvl_chat.configuration_internvl_chat | max_dynamic_patch: 6
2024-05-29 21:10:21 | INFO | internvl.model.internvl_chat.modeling_internvl_chat | num_image_token: 256
2024-05-29 21:10:21 | INFO | internvl.model.internvl_chat.modeling_internvl_chat | ps_version: v1
2024-05-29 21:10:25 | INFO | stdout | trainable params: 72,351,744 || all params: 19,933,612,032 || trainable%: 0.3630
2024-05-29 21:10:27 | INFO | accelerate.utils.modeling | We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
2024-05-29 21:10:31 | ERROR | stderr | Loading checkpoint shards:   0%|          | 0/11 [00:00<?, ?it/s]
2024-05-29 21:10:36 | ERROR | stderr | Loading checkpoint shards:   9%|▉         | 1/11 [00:04<00:42,  4.27s/it]
2024-05-29 21:10:38 | ERROR | stderr | Loading checkpoint shards:  18%|█▊        | 2/11 [00:06<00:28,  3.12s/it]
2024-05-29 21:10:40 | ERROR | stderr | Loading checkpoint shards:  27%|██▋       | 3/11 [00:08<00:21,  2.69s/it]
2024-05-29 21:10:42 | ERROR | stderr | Loading checkpoint shards:  36%|███▋      | 4/11 [00:10<00:17,  2.51s/it]
2024-05-29 21:10:45 | ERROR | stderr | Loading checkpoint shards:  45%|████▌     | 5/11 [00:13<00:14,  2.38s/it]
2024-05-29 21:10:47 | ERROR | stderr | Loading checkpoint shards:  55%|█████▍    | 6/11 [00:15<00:11,  2.30s/it]
2024-05-29 21:10:49 | ERROR | stderr | Loading checkpoint shards:  64%|██████▎   | 7/11 [00:17<00:09,  2.28s/it]
2024-05-29 21:10:51 | ERROR | stderr | Loading checkpoint shards:  73%|███████▎  | 8/11 [00:19<00:06,  2.24s/it]
2024-05-29 21:10:53 | ERROR | stderr | Loading checkpoint shards:  82%|████████▏ | 9/11 [00:21<00:04,  2.20s/it]
2024-05-29 21:10:55 | ERROR | stderr | Loading checkpoint shards:  91%|█████████ | 10/11 [00:23<00:02,  2.19s/it]
2024-05-29 21:10:56 | ERROR | stderr | Loading checkpoint shards: 100%|██████████| 11/11 [00:24<00:00,  1.80s/it]
2024-05-29 21:10:56 | ERROR | stderr | Loading checkpoint shards: 100%|██████████| 11/11 [00:24<00:00,  2.26s/it]
2024-05-29 21:10:56 | ERROR | stderr | 
2024-05-29 21:10:57 | INFO | model_worker | Register to controller
2024-05-29 21:10:57 | ERROR | stderr | INFO:     Started server process [110844]
2024-05-29 21:10:57 | ERROR | stderr | INFO:     Waiting for application startup.
2024-05-29 21:10:57 | ERROR | stderr | INFO:     Application startup complete.
2024-05-29 21:10:57 | ERROR | stderr | INFO:     Uvicorn running on http://0.0.0.0:10014 (Press CTRL+C to quit)
2024-05-29 21:11:12 | INFO | model_worker | Send heart beat. Models: ['test']. Semaphore: None. global_counter: 0
2024-05-29 21:11:12 | INFO | stdout | INFO:     10.140.24.69:48978 - "POST /worker_get_status HTTP/1.1" 200 OK
2024-05-29 21:11:22 | INFO | model_worker | Send heart beat. Models: ['test']. Semaphore: Semaphore(value=4, locked=False). global_counter: 1
2024-05-29 21:11:22 | INFO | stdout | INFO:     10.140.24.69:48986 - "POST /worker_generate_stream HTTP/1.1" 200 OK
2024-05-29 21:11:22 | INFO | model_worker | max_input_tiles: 12
2024-05-29 21:11:22 | INFO | model_worker | dynamic_image_size: False
2024-05-29 21:11:22 | INFO | model_worker | use_thumbnail: False
2024-05-29 21:11:22 | INFO | model_worker | Resize images to 448x448
2024-05-29 21:11:22 | INFO | model_worker | Split images to torch.Size([1, 3, 448, 448])
2024-05-29 21:11:22 | INFO | model_worker | A chat between a curious user and an artificial intelligence assistant. The assistant gives helpful, detailed, and polite answers to the user's questions. USER: <img><image></img>
描述这张图 ASSISTANT:
2024-05-29 21:11:22 | INFO | model_worker | num_image_tokens: 256
2024-05-29 21:11:22 | INFO | model_worker | max_new_tokens: 1024
2024-05-29 21:11:27 | INFO | model_worker | Send heart beat. Models: ['test']. Semaphore: Semaphore(value=4, locked=False). global_counter: 1
2024-05-29 21:11:27 | ERROR | stderr | /mnt/petrelfs/zhangdi1/lijunxian/InternVL/internvl_chat/internvl/model/internvl_chat/modeling_internvl_chat.py:198: UserWarning: In ps_version 'v1', the height and width have not been swapped back, which results in a transposed image.
2024-05-29 21:11:27 | ERROR | stderr |   warnings.warn("In ps_version 'v1', the height and width have not been swapped back, "
2024-05-29 21:11:42 | INFO | model_worker | Send heart beat. Models: ['test']. Semaphore: Semaphore(value=4, locked=False). global_counter: 1
2024-05-29 21:11:57 | INFO | model_worker | Send heart beat. Models: ['test']. Semaphore: Semaphore(value=4, locked=False). global_counter: 1
2024-05-29 21:12:12 | INFO | model_worker | Send heart beat. Models: ['test']. Semaphore: Semaphore(value=4, locked=False). global_counter: 1
2024-05-29 21:12:18 | INFO | model_worker | Send heart beat. Models: ['test']. Semaphore: Semaphore(value=5, locked=False). global_counter: 1
2024-05-29 21:12:18 | INFO | stdout | INFO:     10.140.24.69:49020 - "POST /worker_get_status HTTP/1.1" 200 OK
2024-05-29 21:12:27 | INFO | model_worker | Send heart beat. Models: ['test']. Semaphore: Semaphore(value=5, locked=False). global_counter: 1
2024-05-29 21:12:42 | INFO | model_worker | Send heart beat. Models: ['test']. Semaphore: Semaphore(value=5, locked=False). global_counter: 1
2024-05-29 21:12:57 | INFO | model_worker | Send heart beat. Models: ['test']. Semaphore: Semaphore(value=5, locked=False). global_counter: 1
2024-05-29 21:13:12 | INFO | model_worker | Send heart beat. Models: ['test']. Semaphore: Semaphore(value=5, locked=False). global_counter: 1
2024-05-29 21:13:27 | INFO | model_worker | Send heart beat. Models: ['test']. Semaphore: Semaphore(value=5, locked=False). global_counter: 1
2024-05-29 21:13:43 | INFO | model_worker | Send heart beat. Models: ['test']. Semaphore: Semaphore(value=5, locked=False). global_counter: 1
2024-05-29 21:13:58 | INFO | model_worker | Send heart beat. Models: ['test']. Semaphore: Semaphore(value=5, locked=False). global_counter: 1
2024-05-29 21:14:13 | INFO | model_worker | Send heart beat. Models: ['test']. Semaphore: Semaphore(value=5, locked=False). global_counter: 1
2024-05-29 21:14:28 | INFO | model_worker | Send heart beat. Models: ['test']. Semaphore: Semaphore(value=5, locked=False). global_counter: 1
2024-05-29 21:14:43 | INFO | model_worker | Send heart beat. Models: ['test']. Semaphore: Semaphore(value=5, locked=False). global_counter: 1
slurmstepd: error: *** JOB 3517399 ON SH-IDC1-10-140-24-69 CANCELLED AT 2024-05-29T21:14:56 ***
